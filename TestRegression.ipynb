{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stackregression import stack_regression, stack_prediction, get_prediction, print_prediction_report\n",
    "from utils import encode_numeric_zscore_list, encode_numeric_zscore_all, to_xy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read Input CSV file\n",
    "path = \"./data/self\"\n",
    "inputFilePath = os.path.join(path, \"TestRegression.csv\")\n",
    "#df = pd.read_csv(inputFilePath, compression=\"zip\", header=0, na_values=['NULL'])\n",
    "df = pd.read_csv(inputFilePath, header=0, na_values=['NULL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "['A', 'B', 'C', 'D', 'Label']\n",
      "Epoch 1/10\n",
      "666/666 [==============================] - 0s - loss: 360.4357     \n",
      "Epoch 2/10\n",
      "666/666 [==============================] - 1s - loss: 324.0519     \n",
      "Epoch 3/10\n",
      "666/666 [==============================] - 0s - loss: 224.8281     \n",
      "Epoch 4/10\n",
      "666/666 [==============================] - 0s - loss: 118.6471     \n",
      "Epoch 5/10\n",
      "666/666 [==============================] - 1s - loss: 71.3714     \n",
      "Epoch 6/10\n",
      "666/666 [==============================] - 0s - loss: 57.5920     \n",
      "Epoch 7/10\n",
      "666/666 [==============================] - 0s - loss: 51.8882     \n",
      "Epoch 8/10\n",
      "666/666 [==============================] - 0s - loss: 52.9071     \n",
      "Epoch 9/10\n",
      "666/666 [==============================] - 0s - loss: 51.7914     \n",
      "Epoch 10/10\n",
      "666/666 [==============================] - 1s - loss: 46.9312     \n",
      "Epoch 1/10\n",
      "667/667 [==============================] - 1s - loss: 347.5959     \n",
      "Epoch 2/10\n",
      "667/667 [==============================] - 1s - loss: 313.9388     \n",
      "Epoch 3/10\n",
      "667/667 [==============================] - 1s - loss: 237.1385     \n",
      "Epoch 4/10\n",
      "667/667 [==============================] - 0s - loss: 148.3467     \n",
      "Epoch 5/10\n",
      "667/667 [==============================] - 1s - loss: 81.5425     \n",
      "Epoch 6/10\n",
      "667/667 [==============================] - 1s - loss: 57.6724     \n",
      "Epoch 7/10\n",
      "667/667 [==============================] - 1s - loss: 49.3887     \n",
      "Epoch 8/10\n",
      "667/667 [==============================] - 1s - loss: 51.1733     \n",
      "Epoch 9/10\n",
      "667/667 [==============================] - 1s - loss: 45.8862     \n",
      "Epoch 10/10\n",
      "667/667 [==============================] - 1s - loss: 46.7200     \n",
      "Epoch 1/10\n",
      "667/667 [==============================] - 0s - loss: 360.5572     \n",
      "Epoch 2/10\n",
      "667/667 [==============================] - 1s - loss: 330.8896     \n",
      "Epoch 3/10\n",
      "667/667 [==============================] - 1s - loss: 242.8088     \n",
      "Epoch 4/10\n",
      "667/667 [==============================] - 1s - loss: 126.0297     \n",
      "Epoch 5/10\n",
      "667/667 [==============================] - 0s - loss: 70.0783     \n",
      "Epoch 6/10\n",
      "667/667 [==============================] - 0s - loss: 59.4428     \n",
      "Epoch 7/10\n",
      "667/667 [==============================] - 1s - loss: 55.1027     \n",
      "Epoch 8/10\n",
      "667/667 [==============================] - 0s - loss: 49.4652     \n",
      "Epoch 9/10\n",
      "667/667 [==============================] - 1s - loss: 46.6991     \n",
      "Epoch 10/10\n",
      "667/667 [==============================] - 0s - loss: 47.1406     \n",
      " 992/1000 [============================>.] - ETA: 0sStep 1 Predictions:\n",
      "---------------------------------------------\n",
      "RMSE: 24.933869209307783; EVS:0.9947373828693614; R2score:0.9944749633862878\n",
      "---------------------------------------------\n",
      "Epoch 1/10\n",
      "666/666 [==============================] - 0s - loss: 361.9133     \n",
      "Epoch 2/10\n",
      "666/666 [==============================] - 1s - loss: 326.1370     \n",
      "Epoch 3/10\n",
      "666/666 [==============================] - 0s - loss: 190.8306     \n",
      "Epoch 4/10\n",
      "666/666 [==============================] - 0s - loss: 74.7730     \n",
      "Epoch 5/10\n",
      "666/666 [==============================] - 1s - loss: 63.9832     \n",
      "Epoch 6/10\n",
      "666/666 [==============================] - 1s - loss: 58.6430     \n",
      "Epoch 7/10\n",
      "666/666 [==============================] - 0s - loss: 50.6730     \n",
      "Epoch 8/10\n",
      "666/666 [==============================] - 1s - loss: 44.2239     \n",
      "Epoch 9/10\n",
      "666/666 [==============================] - 1s - loss: 41.2860     \n",
      "Epoch 10/10\n",
      "666/666 [==============================] - 1s - loss: 39.2654     \n",
      "Epoch 1/10\n",
      "667/667 [==============================] - 0s - loss: 345.6612     \n",
      "Epoch 2/10\n",
      "667/667 [==============================] - 0s - loss: 313.3363     \n",
      "Epoch 3/10\n",
      "667/667 [==============================] - 1s - loss: 205.4105     \n",
      "Epoch 4/10\n",
      "667/667 [==============================] - 1s - loss: 74.6782     \n",
      "Epoch 5/10\n",
      "667/667 [==============================] - 1s - loss: 63.4550     \n",
      "Epoch 6/10\n",
      "667/667 [==============================] - 1s - loss: 56.3778     \n",
      "Epoch 7/10\n",
      "667/667 [==============================] - 0s - loss: 50.7817     \n",
      "Epoch 8/10\n",
      "667/667 [==============================] - 0s - loss: 44.2714     \n",
      "Epoch 9/10\n",
      "667/667 [==============================] - 0s - loss: 40.5515     \n",
      "Epoch 10/10\n",
      "667/667 [==============================] - 0s - loss: 38.5377     \n",
      "Epoch 1/10\n",
      "667/667 [==============================] - 0s - loss: 361.7675     \n",
      "Epoch 2/10\n",
      "667/667 [==============================] - 0s - loss: 329.8521     \n",
      "Epoch 3/10\n",
      "667/667 [==============================] - 0s - loss: 203.6362     \n",
      "Epoch 4/10\n",
      "667/667 [==============================] - 0s - loss: 73.4967     \n",
      "Epoch 5/10\n",
      "667/667 [==============================] - 0s - loss: 64.3221     \n",
      "Epoch 6/10\n",
      "667/667 [==============================] - 1s - loss: 56.7074     \n",
      "Epoch 7/10\n",
      "667/667 [==============================] - 1s - loss: 46.6968     \n",
      "Epoch 8/10\n",
      "667/667 [==============================] - 0s - loss: 42.4929     \n",
      "Epoch 9/10\n",
      "667/667 [==============================] - 1s - loss: 36.8622     \n",
      "Epoch 10/10\n",
      "667/667 [==============================] - 1s - loss: 35.6164     \n",
      " 992/1000 [============================>.] - ETA: 0sStep 2 Predictions:\n",
      "---------------------------------------------\n",
      "RMSE: 14.806695240252738; EVS:0.998065215475061; R2score:0.9980516270949814\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#shuffle dataset. Unnecessary in this case because already sorted by guid\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "#df.drop('id', axis=1, inplace=True)\n",
    "#encode categoricals as dummies\n",
    "\n",
    "#encode_text_dummy_list(df, ['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18', 'cat19', 'cat20', 'cat21', 'cat22', 'cat23', 'cat24', 'cat25', 'cat26', 'cat27', 'cat28', 'cat29', 'cat30', 'cat31', 'cat32', 'cat33', 'cat34', 'cat35', 'cat36', 'cat37', 'cat38', 'cat39', 'cat40', 'cat41', 'cat42', 'cat43', 'cat44', 'cat45', 'cat46', 'cat47', 'cat48', 'cat49', 'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56', 'cat57', 'cat58', 'cat59', 'cat60', 'cat61', 'cat62', 'cat63', 'cat64', 'cat65', 'cat66', 'cat67', 'cat68', 'cat69', 'cat70', 'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76', 'cat77', 'cat78', 'cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84', 'cat85', 'cat86', 'cat87', 'cat88', 'cat89', 'cat90', 'cat91', 'cat92', 'cat93', 'cat94', 'cat95', 'cat96', 'cat97', 'cat98', 'cat99', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104', 'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat110', 'cat111', 'cat112', 'cat113', 'cat114', 'cat115', 'cat116'])\n",
    "\n",
    "#encode all numeric values to zscored values\n",
    "#encode_numeric_zscore(df, 'AW')\n",
    "\n",
    "#encode_numeric_log_list(df, ['A', 'B', 'C', 'D'])\n",
    "encode_numeric_zscore_list(df, ['A', 'B', 'C', 'D'])\n",
    "\n",
    "#discard rows where z-score > 2\n",
    "df.fillna(0)\n",
    "\n",
    "# Create x(predictors) and y (expected outcome)\n",
    "x,y = to_xy(df, \"Label\")\n",
    "x = preprocessing.StandardScaler().fit_transform(x)\n",
    "x = x.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "headers = list(df.columns.values)\n",
    "print(headers)\n",
    "#print(df.columns.values)\n",
    "\n",
    "    \n",
    "step1predictions, learners = stack_regression(x, y)\n",
    "print(\"Step 1 Predictions:\")\n",
    "print(\"---------------------------------------------\")\n",
    "print_prediction_report(step1predictions, y)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "encode_numeric_zscore_all(step1predictions)\n",
    "x = np.concatenate((x, step1predictions), axis=1)\n",
    "x = x.astype(np.float32)\n",
    "step2predictions, step2_learners = stack_regression(x, y)\n",
    "\n",
    "print(\"Step 2 Predictions:\")\n",
    "print(\"---------------------------------------------\")\n",
    "print_prediction_report(step2predictions, y)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "#encode_numeric_zscore_all(step1predictions_ytest)\n",
    "#x_test = np.concatenate((x_test, step1predictions_ytest), axis=1)\n",
    "#x_test = x_test.astype(np.float32)\n",
    "#step2predictions_ytest = stack_prediction(x_test, y_test, step2_learners)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
