{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Baysian hyperparameter optimization [https://github.com/fmfn/BayesianOptimization]\n",
    "for Mean Absoulte Error objective\n",
    "on default features for https://www.kaggle.com/c/allstate-claims-severity\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Vladimir Iglovikov\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 627.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[26]\ttrain-mae:1160.06+10.3619\ttest-mae:1303.72+52.9484\n",
      "\n",
      "    1 | 00m01s | \u001b[35m-1303.71733\u001b[0m | \u001b[32m  15.9118\u001b[0m | \u001b[32m            0.8436\u001b[0m | \u001b[32m  19.5128\u001b[0m | \u001b[32m    41.1343\u001b[0m | \u001b[32m           29.8087\u001b[0m | \u001b[32m     0.3912\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[23]\ttrain-mae:759.988+10.3987\ttest-mae:1289.41+36.4478\n",
      "\n",
      "    2 | 00m01s | \u001b[35m-1289.40584\u001b[0m | \u001b[32m  27.2547\u001b[0m | \u001b[32m            0.4422\u001b[0m | \u001b[32m   7.3513\u001b[0m | \u001b[32m    49.2704\u001b[0m | \u001b[32m           12.5711\u001b[0m | \u001b[32m     0.7972\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[117]\ttrain-mae:2101.13+210.337\ttest-mae:2102.28+194.247\n",
      "\n",
      "    3 | 00m01s | -2102.28472 |   10.3205 |             0.7323 |   46.2793 |      8.8176 |            24.2801 |      0.0104 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-mae:1159.72+17.6586\ttest-mae:1312.58+64.3994\n",
      "\n",
      "    4 | 00m01s | -1312.57510 |   26.4966 |             0.3325 |   46.2954 |     22.9669 |            43.1862 |      0.5021 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[29]\ttrain-mae:1064.6+14.2422\ttest-mae:1299.43+55.4582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "\n",
    "    cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,\n",
    "             seed=random_state,\n",
    "             callbacks=[xgb.callback.early_stop(20)])\n",
    "\n",
    "    return -cv_result['test-mae-mean'].values[-1]\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "    path = \"./data/allstate\"\n",
    "    inputFilePath = os.path.join(path, \"train.csv.zip\")\n",
    "    train = pd.read_csv(inputFilePath, compression=\"zip\", header=0)\n",
    "    train = train.sample(frac=0.01)\n",
    "    categorical_columns = train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for column in tqdm(categorical_columns):\n",
    "        le = LabelEncoder()\n",
    "        train[column] = le.fit_transform(train[column])\n",
    "\n",
    "    y = train['loss']\n",
    "\n",
    "    X = train.drop(['loss', 'id'], 1)\n",
    "    xgtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "    return xgtrain\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    xgtrain = prepare_data()\n",
    "\n",
    "    num_rounds = 100000\n",
    "    random_state = 2016\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'eval_metric': 'mae',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "    xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 50),\n",
    "                                                'colsample_bytree': (0, 1),\n",
    "                                                'max_depth': (5, 50),\n",
    "                                                'subsample': (0, 1),\n",
    "                                                'gamma': (0, 50),\n",
    "                                                'alpha': (0, 50),\n",
    "                                                })\n",
    "\n",
    "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
