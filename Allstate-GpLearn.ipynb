{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arvc/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape of X Train=(188318, 130)\n",
      "    |    Population Average   |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0     10.3  0.0872788528636       12 0.40716130032998166   0.426128990436     18.73s\n",
      "   1    10.51   0.254186590825        8 0.48745896871708355   0.490173482329     18.57s\n",
      "   2    12.04    0.34583172643        8 0.4880700250142873   0.484602244015     13.39s\n",
      "   3     9.32   0.381700294873       13 0.5263190018162145   0.527946454182      6.92s\n",
      "   4    10.57   0.397828543125       13 0.5442510018216578   0.541585345789      0.00s\n",
      "New shape of X Train=(188318, 140)\n",
      "Old shape of X Test=(125546, 130)\n",
      "New shape of X Test=(125546, 140)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from random import randint\n",
    "from gplearn.genetic import SymbolicRegressor, SymbolicTransformer\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "train = pd.read_csv('./data/allstate/train.csv')\n",
    "test = pd.read_csv('./data/allstate/test.csv')\n",
    "\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])\n",
    "\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    con = 2\n",
    "    x =preds-labels\n",
    "    grad =con*x / (np.abs(x)+con)\n",
    "    hess =con**2 / (np.abs(x)+con)**2\n",
    "    return grad, hess \n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))\n",
    "\n",
    "\n",
    "cat_feature = [n for n in joined.columns if n.startswith('cat')]    \n",
    "cont_feature = [n for n in joined.columns if n.startswith('cont')] \n",
    "             \n",
    "               \n",
    "\n",
    "for column in cat_feature:\n",
    "    joined[column] = pd.factorize(joined[column].values, sort=True)[0]\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 202\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "\n",
    "print(\"Old shape of X Train={}\".format(X.shape))\n",
    "\n",
    "gp = SymbolicTransformer(generations=5, population_size=100,\n",
    "                     hall_of_fame=100, n_components=10,                         \n",
    "                     parsimony_coefficient=0.0005,\n",
    "                     max_samples=0.9, verbose=1,\n",
    "                     random_state=0, n_jobs=10)\n",
    "gp.fit(X, y)\n",
    "gp_features_train = gp.transform(X)        \n",
    "X = np.hstack((X, gp_features_train))\n",
    "\n",
    "print(\"New shape of X Train={}\".format(X.shape)) \n",
    "\n",
    "print(\"Old shape of X Test={}\".format(X_test.shape)) \n",
    "gp_features_test = gp.transform(X_test)        \n",
    "X_test = np.hstack((X_test, gp_features_test))\n",
    "\n",
    "print(\"New shape of X Test={}\".format(X_test.shape))    \n",
    "\n",
    "#X = X.sample(frac=0.1)\n",
    "#y = y .iloc[X.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1\n",
      "[0]\ttrain-mae:3237.39\teval-mae:3238.84\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 300 rounds.\n",
      "[100]\ttrain-mae:3220.64\teval-mae:3222.07\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "n_folds  = 6\n",
    "kf = KFold(X.shape[0], n_folds=n_folds)\n",
    "prediction = np.zeros(ids.shape)\n",
    "\n",
    "final_fold_prediction= []\n",
    "final_fold_real = []\n",
    "\n",
    "partial_evalutaion = open('temp_scores.txt','w')\n",
    "for i, (train_index, test_index) in enumerate(kf):\n",
    "    print('\\n Fold %d' % (i + 1))\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]    \n",
    "\n",
    "    RANDOM_STATE = randint(1,429496)\n",
    "    params = {\n",
    "        'min_child_weight': 1,\n",
    "        'eta': 0.001,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.8,\n",
    "        'alpha': 1,\n",
    "        'gamma': 1,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': False,\n",
    "        'seed': RANDOM_STATE\n",
    "    }\n",
    "\n",
    "    xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    xgtrain_2 = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    xgtest = xgb.DMatrix(X_test)\n",
    "    watchlist = [(xgtrain, 'train'), (xgtrain_2, 'eval')]                    \n",
    "\n",
    "    model = xgb.train(params, xgtrain, 100000, watchlist, obj=logregobj, feval=evalerror, \n",
    "    early_stopping_rounds=300, verbose_eval=100)        \n",
    "    prediction += np.exp(model.predict(xgtest)) - shift\n",
    "\n",
    "    X_val = xgb.DMatrix(X_val) \n",
    "    temp_serises = pd.Series(np.exp(model.predict(X_val))-shift)\n",
    "    final_fold_prediction.append( temp_serises )\n",
    "    temp_serises = np.exp(y_val) -shift\n",
    "    final_fold_real.append(temp_serises )\n",
    "\n",
    "    temp_cv_score = mean_absolute_error(np.exp(model.predict(X_val))-shift, np.exp(y_val) -shift)\n",
    "\n",
    "    partial_evalutaion.write('fold '+str(i)+' '+str(temp_cv_score)+'\\n')\n",
    "    partial_evalutaion.flush()\n",
    "\n",
    "prediction = prediction/n_folds\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = ids    \n",
    "submission['loss'] = prediction\n",
    "\n",
    "submission.to_csv('sub_gp.csv', index=False)\n",
    "\n",
    "final_fold_prediction = pd.concat(final_fold_prediction,ignore_index=True)\n",
    "final_fold_real = pd.concat(final_fold_real,ignore_index=True)\n",
    "\n",
    "cv_score = mean_absolute_error(final_fold_prediction, final_fold_real)\n",
    "print (\"CV Score={}\".format(cv_score))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
