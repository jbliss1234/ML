{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arvc/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape of X Train=(188318, 130)\n",
      "    |    Population Average   |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0     9.78  0.0720975896335        4 0.4889243552056609   0.497015295545     17.07m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from random import randint\n",
    "from gplearn.genetic import SymbolicRegressor, SymbolicTransformer\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "train = pd.read_csv('./data/allstate/train.csv')\n",
    "test = pd.read_csv('./data/allstate/test.csv')\n",
    "\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])\n",
    "\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    con = 2\n",
    "    x =preds-labels\n",
    "    grad =con*x / (np.abs(x)+con)\n",
    "    hess =con**2 / (np.abs(x)+con)**2\n",
    "    return grad, hess \n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))\n",
    "\n",
    "\n",
    "cat_feature = [n for n in joined.columns if n.startswith('cat')]    \n",
    "cont_feature = [n for n in joined.columns if n.startswith('cont')] \n",
    "             \n",
    "               \n",
    "if __name__ == '__main__':   \n",
    "    for column in cat_feature:\n",
    "        joined[column] = pd.factorize(joined[column].values, sort=True)[0]\n",
    "    \n",
    "    train = joined[joined['loss'].notnull()]\n",
    "    test = joined[joined['loss'].isnull()]\n",
    "\n",
    "    shift = 202\n",
    "    y = np.log(train['loss'] + shift)\n",
    "    ids = test['id']\n",
    "    X = train.drop(['loss', 'id'], 1)\n",
    "    X_test = test.drop(['loss', 'id'], 1)\n",
    "    \n",
    "    print(\"Old shape of X Train={}\".format(X.shape))\n",
    "    \n",
    "    gp = SymbolicTransformer(generations=20, population_size=2000,\n",
    "                         hall_of_fame=100, n_components=10,                         \n",
    "                         parsimony_coefficient=0.0005,\n",
    "                         max_samples=0.9, verbose=1,\n",
    "                         random_state=0, n_jobs=3)\n",
    "    gp.fit(X, y)\n",
    "    gp_features_train = gp.transform(X)        \n",
    "    X = np.hstack((X, gp_features_train))\n",
    "    \n",
    "    print(\"New shape of X Train={}\".format(X.shape)) \n",
    "    \n",
    "    print(\"Old shape of X Test={}\".format(X_test.shape)) \n",
    "    gp_features_test = gp.transform(X_test)        \n",
    "    X_test = np.hstack((X_test, gp_features_test))\n",
    "    \n",
    "    print(\"New shape of X Test={}\".format(X_test.shape))    \n",
    "        \n",
    "    #X = X.sample(frac=0.1)\n",
    "    #y = y .iloc[X.index.values]\n",
    "    \n",
    "    n_folds  = 6\n",
    "    kf = KFold(X.shape[0], n_folds=n_folds)\n",
    "    prediction = np.zeros(ids.shape)\n",
    "    \n",
    "    final_fold_prediction= []\n",
    "    final_fold_real = []\n",
    "\n",
    "    partial_evalutaion = open('temp_scores.txt','w')\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\n Fold %d' % (i + 1))\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]    \n",
    "        \n",
    "        RANDOM_STATE = randint(1,429496)\n",
    "        params = {\n",
    "            'min_child_weight': 1,\n",
    "            'eta': 0.001,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'max_depth': 12,\n",
    "            'subsample': 0.8,\n",
    "            'alpha': 1,\n",
    "            'gamma': 1,\n",
    "            'silent': 1,\n",
    "            'verbose_eval': False,\n",
    "            'seed': RANDOM_STATE\n",
    "        }\n",
    "    \n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        xgtrain_2 = xgb.DMatrix(X_val, label=y_val)\n",
    "        \n",
    "        xgtest = xgb.DMatrix(X_test)\n",
    "        watchlist = [(xgtrain, 'train'), (xgtrain_2, 'eval')]                    \n",
    "\n",
    "        model = xgb.train(params, xgtrain, 100000, watchlist, obj=logregobj, feval=evalerror, \n",
    "        early_stopping_rounds=300, verbose_eval=100)        \n",
    "        prediction += np.exp(model.predict(xgtest)) - shift\n",
    "\n",
    "        X_val = xgb.DMatrix(X_val) \n",
    "        temp_serises = pd.Series(np.exp(model.predict(X_val))-shift)\n",
    "        final_fold_prediction.append( temp_serises )\n",
    "        temp_serises = np.exp(y_val) -shift\n",
    "        final_fold_real.append(temp_serises )\n",
    "        \n",
    "        temp_cv_score = mean_absolute_error(np.exp(model.predict(X_val))-shift, np.exp(y_val) -shift)\n",
    "        \n",
    "        partial_evalutaion.write('fold '+str(i)+' '+str(temp_cv_score)+'\\n')\n",
    "        partial_evalutaion.flush()\n",
    "                \n",
    "\n",
    "    \n",
    "    prediction = prediction/n_folds\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id'] = ids    \n",
    "    submission['loss'] = prediction\n",
    "\n",
    "    submission.to_csv('sub_gp.csv', index=False)\n",
    "    \n",
    "    final_fold_prediction = pd.concat(final_fold_prediction,ignore_index=True)\n",
    "    final_fold_real = pd.concat(final_fold_real,ignore_index=True)\n",
    "    \n",
    "    cv_score = mean_absolute_error(final_fold_prediction, final_fold_real)\n",
    "    print (\"CV Score={}\".format(cv_score))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
